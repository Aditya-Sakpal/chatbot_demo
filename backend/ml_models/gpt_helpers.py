from openai import OpenAI
from constants.credentials import OPENAI_API_KEY, OPENAI_ORGANIZATION
import re
import tiktoken
from constants.common import EMBEDDING_MODEL

tokenizer = None


client = OpenAI(
    api_key=OPENAI_API_KEY,
    organization=OPENAI_ORGANIZATION
  )

def openai_prompt_to_gemini(openai_final_prompt):
    """
        Convert OpenAI prompt format to Gemini prompt format.

        Args:
        - openai_final_prompt (list): List containing dictionaries representing parts of the prompt in OpenAI format.

        Returns:
        - tuple: A tuple containing two elements:
            - gemini_final_prompt (dict): A dictionary representing the final prompt in Gemini format.
            - history (list): A list containing dictionaries representing the history of the conversation in Gemini format.
    """
    gemini_final_prompt = {
        "role": "user",
        "parts": [
            {
                "text": (openai_final_prompt[-1]["content"])
            }
        ]
    }
    history = []
    for entry in openai_final_prompt[:-1]:
        role = entry['role']
        content = entry['content']
        if role == "system" or role == "assistant":
            role = "model"
        history.append({
            "role": role,
            "parts": [
                {
                    "text": (content)
                }
            ]
        })
    
    return gemini_final_prompt, history

# TODO: Surround with tru catch, look for fallback if openai is down
def create_embedding(text):
    """
        This function takes a string of text, removes newline characters by replacing them with spaces,
        and then generates an embedding using the specified embedding model from OpenAI.

        Args:
            text (str): The input text to generate an embedding for.

        Returns:
            list: The embedding vector generated by the OpenAI API.
    """
    text = re.sub(r'\s+', ' ',text)
    return client.embeddings.create(input=text, model=EMBEDDING_MODEL).data[0].embedding


def create_embedding_for_list(text_list):
    for _, i in enumerate(text_list):
        text_list[i] = re.sub(r'\s+', ' ', text_list[i])

    embed_data = client.embeddings.create(input=text_list, model=EMBEDDING_MODEL).data
    return [record.embedding for record in embed_data]




def count_tokens_tiktoken(text):
    encoding = "cl100k_base"
    encoding = tiktoken.get_encoding(encoding)
    return len(encoding.encode(text))


###################### UNUSED FUNCTIONS #####################
# def count_tokens_gpt(text: str) -> int:
#     global tokenizer
#     if tokenizer is None:
#         tokenizer = GPT2TokenizerFast.from_pretrained("gpt2")
#     if len(text) > 2000:
#         return len(text)
#     """count the number of tokens in a string"""
#     return len(tokenizer.encode(text))
